<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="ie=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><link rel=preload as=font href=https://gambitbsm.org/fonts/vendor/jost/jost-v4-latin-regular.woff2 type=font/woff2 crossorigin><link rel=preload as=font href=https://gambitbsm.org/fonts/vendor/jost/jost-v4-latin-500.woff2 type=font/woff2 crossorigin><link rel=preload as=font href=https://gambitbsm.org/fonts/vendor/jost/jost-v4-latin-700.woff2 type=font/woff2 crossorigin><script>(()=>{var e=localStorage.getItem("theme");e==="dark"&&document.documentElement.setAttribute("data-dark-mode","")})()</script><link rel=stylesheet href=https://gambitbsm.org/main.e0ef67572fa591316dbb2b276e1aed52fd04025355d700a37b20ae76eb126fadbe7ceaddbb47632a2f1bf66c490a69e0cd1f1a0dc12b2980ae4b5ffc6d257d62.css integrity="sha512-4O9nVy+lkTFtuysnbhrtUv0EAlNV1wCjeyCudusSb62+fOrdu0djKi8b9mxJCmngzR8aDcErKYCuS1/8bSV9Yg==" crossorigin=anonymous><noscript><style>img.lazyload{display:none}</style></noscript><meta name=robots content="index, follow"><meta name=googlebot content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"><meta name=bingbot content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"><title>file src/LHC_likelihoods.cpp - GAMBIT</title><meta name=description content="[No description available]"><link rel=canonical href=https://gambitbsm.org/documentation/code/files/lhc__likelihoods_8cpp/><meta property="og:locale" content="en_US"><meta property="og:type" content="article"><meta property="og:title" content="file src/LHC_likelihoods.cpp"><meta property="og:description" content="[No description available]"><meta property="og:url" content="https://gambitbsm.org/documentation/code/files/lhc__likelihoods_8cpp/"><meta property="og:site_name" content="GAMBIT"><meta property="og:image" content="https://gambitbsm.org/gambit_logo.png"><meta property="og:image:alt" content="GAMBIT"><meta name=twitter:card content="summary_large_image"><meta name=twitter:site content><meta name=twitter:creator content><meta name=twitter:title content="file src/LHC_likelihoods.cpp"><meta name=twitter:description content="[No description available]"><meta name=twitter:image content="https://gambitbsm.org/gambit_logo.png"><meta name=twitter:image:alt content="file src/LHC_likelihoods.cpp"><script type=application/ld+json>{"@context":"https://schema.org","@graph":[{"@type":"Organization","@id":"https://gambitbsm.org/#/schema/organization/1","name":"Doks","url":"https://gambitbsm.org/","sameAs":["https://github.com/GambitBSM"],"logo":{"@type":"ImageObject","@id":"https://gambitbsm.org/#/schema/image/1","url":"https://gambitbsm.org/logo-doks.png","width":450,"height":416,"caption":"Doks"},"image":{"@id":"https://gambitbsm.org/#/schema/image/1"}},{"@type":"WebSite","@id":"https://gambitbsm.org/#/schema/website/1","url":"https://gambitbsm.org/","name":"GAMBIT","description":"Documentation for GAMBIT, the Global And Modular BSM Inference Tool","publisher":{"@id":"https://gambitbsm.org/#/schema/organization/1"}},{"@type":"WebPage","@id":"https://gambitbsm.org/documentation/code/files/lhc__likelihoods_8cpp/","url":"https://gambitbsm.org/documentation/code/files/lhc__likelihoods_8cpp/","name":"file src\/LHC_likelihoods.cpp","description":"[No description available]","isPartOf":{"@id":"https://gambitbsm.org/#/schema/website/1"},"about":{"@id":"https://gambitbsm.org/#/schema/organization/1"},"datePublished":"0001-01-01T00:00:00CET","dateModified":"0001-01-01T00:00:00CET","breadcrumb":{"@id":"https://gambitbsm.org/documentation/code/files/lhc__likelihoods_8cpp/#/schema/breadcrumb/1"},"primaryImageOfPage":{"@id":"https://gambitbsm.org/documentation/code/files/lhc__likelihoods_8cpp/#/schema/image/2"},"inLanguage":"en-US","potentialAction":[{"@type":"ReadAction","target":["https://gambitbsm.org/documentation/code/files/lhc__likelihoods_8cpp/"]}]},{"@type":"BreadcrumbList","@id":"https://gambitbsm.org/documentation/code/files/lhc__likelihoods_8cpp/#/schema/breadcrumb/1","name":"Breadcrumbs","itemListElement":[{"@type":"ListItem","position":1,"item":{"@type":"WebPage","@id":"https://gambitbsm.org/","url":"https://gambitbsm.org/","name":"Home"}},{"@type":"ListItem","position":2,"item":{"@type":"WebPage","@id":"https://gambitbsm.org/documentation/","url":"https://gambitbsm.org/documentation/","name":"Documentation"}},{"@type":"ListItem","position":3,"item":{"@type":"WebPage","@id":"https://gambitbsm.org/documentation/code/","url":"https://gambitbsm.org/documentation/code/","name":"Code"}},{"@type":"ListItem","position":4,"item":{"@type":"WebPage","@id":"https://gambitbsm.org/documentation/code/files/","url":"https://gambitbsm.org/documentation/code/files/","name":"Files"}},{"@type":"ListItem","position":5,"item":{"@id":"https://gambitbsm.org/documentation/code/files/lhc__likelihoods_8cpp/"}}]},{"@context":"https://schema.org","@graph":[{"@type":"ImageObject","@id":"https://gambitbsm.org/documentation/code/files/lhc__likelihoods_8cpp/#/schema/image/2","url":"https://gambitbsm.org/gambit_logo.png","contentUrl":"https://gambitbsm.org/gambit_logo.png","caption":"file src\/LHC_likelihoods.cpp"}]}]}</script><meta name=theme-color content="#fff"><link rel=icon href=https://gambitbsm.org/favicon.ico sizes=any><link rel=icon type=image/svg+xml href=https://gambitbsm.org/favicon.svg><link rel=apple-touch-icon sizes=180x180 href=https://gambitbsm.org/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=https://gambitbsm.org/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://gambitbsm.org/favicon-16x16.png><link rel=manifest crossorigin=use-credentials href=https://gambitbsm.org/site.webmanifest></head><body class="documentation single light"><div class=sticky-top><div class=header-bar></div><header class="navbar navbar-expand-md navbar-light doks-navbar"><nav class="container-xxl flex-wrap flex-md-nowrap" aria-label="Main navigation"><a class="navbar-brand p-0 me-auto" href=https://gambitbsm.org/ aria-label=GAMBIT><img class=logo-light src=https://gambitbsm.org/gambit_logo.png width=50px>
<img class="logo-dark d-none" src=https://gambitbsm.org/gambit_logo.png width=50px>
GAMBIT</a>
<button class="btn btn-menu order-2 d-block d-lg-none" type=button data-bs-toggle=offcanvas data-bs-target=#offcanvasDoks aria-controls=offcanvasDoks aria-label="Open main menu"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"/><line x1="3" y1="6" x2="21" y2="6"/><line x1="3" y1="18" x2="21" y2="18"/></svg></button><div class="offcanvas offcanvas-end border-0 py-lg-1" tabindex=-1 id=offcanvasDoks data-bs-backdrop=true aria-labelledby=offcanvasDoksLabel><div class="header-bar d-lg-none"></div><div class="offcanvas-header d-lg-none"><h2 class="h5 offcanvas-title ps-2" id=offcanvasDoksLabel><a class=text-dark href=/>GAMBIT</a></h2><button type=button class="btn-close text-reset me-2" data-bs-dismiss=offcanvas aria-label="Close main menu"></button></div><div class="offcanvas-body p-4 p-lg-0"><ul class="nav flex-column flex-lg-row align-items-lg-center mt-2 mt-lg-0 ms-lg-2 me-lg-auto"><li class="nav-item dropdown"><a class="nav-link dropdown-toggle ps-0 py-1" href=# id=navbarDropdownMenuLink role=button data-bs-toggle=dropdown aria-expanded=false>Releases
<span class=dropdown-caret><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-down"><polyline points="6 9 12 15 18 9"/></svg></span></a><ul class="dropdown-menu dropdown-menu-main shadow rounded border-0" aria-labelledby=navbarDropdownMenuLink><li><a class=dropdown-item href=https://github.com/GambitBSM/gambit_2.6>GAMBIT 2-6 ⧉</a></li><li><a class=dropdown-item href=https://github.com/GambitBSM/gambit_2.5>GAMBIT 2-5 ⧉</a></li><li><a class=dropdown-item href=https://github.com/GambitBSM/gambit_2.4>GAMBIT 2-4 ⧉</a></li><li><a class=dropdown-item href=https://github.com/GambitBSM/gambit_2.3>GAMBIT 2-3 ⧉</a></li><li><a class=dropdown-item href=https://github.com/GambitBSM/gambit_2.2>GAMBIT 2-2 ⧉</a></li><li><a class=dropdown-item href=https://github.com/GambitBSM/gambit_2.1>GAMBIT 2-1 ⧉</a></li><li><a class=dropdown-item href=https://github.com/GambitBSM/gambit_light_1.0>GAMBIT Light ⧉</a></li><li><a class=dropdown-item href=https://github.com/GambitBSM/gambit_2.6/tags>All releases ⧉</a></li></ul></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle ps-0 py-1" href=# id=navbarDropdownMenuLink role=button data-bs-toggle=dropdown aria-expanded=false>Documentation
<span class=dropdown-caret><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-down"><polyline points="6 9 12 15 18 9"/></svg></span></a><ul class="dropdown-menu dropdown-menu-main shadow rounded border-0" aria-labelledby=navbarDropdownMenuLink><li><a class=dropdown-item href=/documentation/installation/introduction/>Installation</a></li><li><a class=dropdown-item href=/documentation/physics/analyses>Physics</a></li><li><a class=dropdown-item href=/documentation/tutorials/the_gambit_interface>Tutorials</a></li><li><a class=dropdown-item href=/documentation/help/common_problems_and_questions/>Help</a></li><li><a class=dropdown-item href=/documentation/code/index_classes>Code Reference</a></li></ul></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle ps-0 py-1" href=# id=navbarDropdownMenuLink role=button data-bs-toggle=dropdown aria-expanded=false>Community
<span class=dropdown-caret><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-down"><polyline points="6 9 12 15 18 9"/></svg></span></a><ul class="dropdown-menu dropdown-menu-main shadow rounded border-0" aria-labelledby=navbarDropdownMenuLink><li><a class=dropdown-item href=https://github.com/GambitBSM/wiki>Wiki</a></li><li><a class=dropdown-item href=/community/publications/>Publications</a></li><li><a class=dropdown-item href=/community/talks/>Talks</a></li><li><a class=dropdown-item href=/community/members/>Members</a></li><li><a class=dropdown-item href=/community/code_of_conduct/>Code of Conduct</a></li><li><a class=dropdown-item href=/community/contact/>Contact</a></li></ul></li></ul><hr class="text-black-50 my-4 d-lg-none"><form class="doks-search position-relative flex-grow-1 ms-lg-auto me-lg-2"><input id=search class="form-control is-search" type=search placeholder="Search site..." aria-label="Search site..." autocomplete=off><div id=suggestions class="shadow bg-white rounded d-none"></div></form><hr class="text-black-50 my-4 d-lg-none"><ul class="nav flex-column flex-lg-row"><li class=nav-item><a class="nav-link social-link" href=https://github.com/GambitBSM><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg><small class="ms-2 d-lg-none">GitHub</small></a></li></ul><hr class="text-black-50 my-4 d-lg-none"><button id=mode class="btn btn-link" type=button aria-label="Toggle user interface mode">
<span class=toggle-dark><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-moon"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg></span><span class=toggle-light><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-sun"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></span></button></div></div></nav></header></div><div class="wrap container-xxl" role=document><div class=content><div class="row flex-xl-nowrap"><div class="col-lg-5 col-xl-4 docs-sidebar"><nav class=docs-links aria-label="Main navigation"><ul class="list-unstyled collapsible-sidebar"><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-installation aria-expanded=false>
Installation</button><div class=collapse id=section-installation><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=/documentation/installation/introduction/>Getting Started</a></li><li><a class="docs-link rounded" href=/documentation/installation/docker_usage/>Docker Usage</a></li><li><a class="docs-link rounded" href=/documentation/installation/installation_for_linux/>Installation for Linux</a></li><li><a class="docs-link rounded" href=/documentation/installation/installation_for_windows/>Installation for Windows</a></li><li><a class="docs-link rounded" href=/documentation/installation/installation_for_macos/>Installation for macOS</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-tutorials aria-expanded=false>
Tutorials</button><div class=collapse id=section-tutorials><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=/documentation/tutorials/the_gambit_interface/>1 - The GAMBIT Interface</a></li><li><a class="docs-link rounded" href=/documentation/tutorials/in_person_tutorials/>In person tutorials</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-physics aria-expanded=false>
Physics</button><div class=collapse id=section-physics><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=/documentation/physics/analyses/>ColliderBit analysis</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-help aria-expanded=false>
Help</button><div class=collapse id=section-help><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=/documentation/help/common_problems_and_questions/>Common Problems and Questions</a></li><li><a class="docs-link rounded" href=/documentation/help/compiler_matrix/>Compiler Matrix</a></li><li><a class="docs-link rounded" href=/documentation/help/known_issues/>Known Issues</a></li><li><a class="docs-link rounded" href=/documentation/help/configuration_examples/>Configuration Examples</a></li><li><a class="docs-link rounded" href=/documentation/help/support/>Support</a></li></ul></div></li><li class=mb-1><button class="btn btn-toggle align-items-center rounded collapsed" data-bs-toggle=collapse data-bs-target=#section-code aria-expanded=false>
Code Reference</button><div class=collapse id=section-code><ul class="btn-toggle-nav list-unstyled fw-normal pb-1 small"><li><a class="docs-link rounded" href=/documentation/code/index_classes/>Classes</a></li><li><a class="docs-link rounded" href=/documentation/code/index_files/>Files</a></li><li><a class="docs-link rounded" href=/documentation/code/index_pages/>Pages</a></li><li><a class="docs-link rounded" href=/documentation/code/index_namespaces/>Namespaces</a></li></ul></div></li></ul></nav></div><nav class="docs-toc d-none d-xl-block col-xl-3" aria-label="Secondary navigation"><div class=d-xl-none><button class="btn btn-outline-primary btn-sm doks-toc-toggle collapsed" type=button data-bs-toggle=collapse data-bs-target=#onThisPage aria-controls=doks-docs-nav aria-expanded=false aria-label="Toggle On this page navigation">
<span>On this page</span>
<span><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" class="doks doks-expand" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>Expand</title><polyline points="7 13 12 18 17 13"/><polyline points="7 6 12 11 17 6"/></svg><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" class="doks doks-collapse" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>Collapse</title><polyline points="17 11 12 6 7 11"/><polyline points="17 18 12 13 7 18"/></svg></span></button><div class=collapse id=onThisPage><div class="card card-body mt-3 py-1"><div class=page-links><nav id=TableOfContents><ul><li><a href=#namespaces>Namespaces</a></li><li><a href=#defines>Defines</a></li><li><a href=#detailed-description>Detailed Description</a></li><li><a href=#macros-documentation>Macros Documentation</a><ul><li><a href=#define-debug-prefix>define DEBUG_PREFIX</a></li></ul></li><li><a href=#source-code>Source code</a></li></ul></nav></div></div></div></div><div class="page-links d-none d-xl-block"><h3>On this page</h3><nav id=TableOfContents><ul><li><a href=#namespaces>Namespaces</a></li><li><a href=#defines>Defines</a></li><li><a href=#detailed-description>Detailed Description</a></li><li><a href=#macros-documentation>Macros Documentation</a><ul><li><a href=#define-debug-prefix>define DEBUG_PREFIX</a></li></ul></li><li><a href=#source-code>Source code</a></li></ul></nav></div></nav><main class="docs-content col-lg-11 col-xl-9 mx-xl-auto"><nav aria-label=breadcrumb><ol class=breadcrumb><li class=breadcrumb-item><a href=/>Home</a></li><li class=breadcrumb-item><a href=/documentation/>Documentation</a></li><li class=breadcrumb-item><a href=/documentation/code/>Code Reference</a></li><li class="breadcrumb-item active" aria-current=page>file src/LHC_likelihoods.cpp</li></ol></nav><p class=lead></p><h1 id=file-src-lhc-likelihoods-cpp>file src/LHC_likelihoods.cpp <a href=#file-src-lhc-likelihoods-cpp class=anchor aria-hidden=true>#</a></h1><p>[No description available] <a href=#detailed-description>More&mldr;</a></p><h2 id=namespaces>Namespaces <a href=#namespaces class=anchor aria-hidden=true>#</a></h2><table><thead><tr><th>Name</th></tr></thead><tbody><tr><td><strong><a href=/documentation/code/namespaces/namespacegambit/>Gambit</a></strong><br>TODO: see if we can use this one:</td></tr><tr><td><strong><a href=/documentation/code/namespaces/namespacegambit_1_1colliderbit/>Gambit::ColliderBit</a></strong></td></tr></tbody></table><h2 id=defines>Defines <a href=#defines class=anchor aria-hidden=true>#</a></h2><table><thead><tr><th></th><th>Name</th></tr></thead><tbody><tr><td></td><td><strong><a href=/documentation/code/files/lhc__likelihoods_8cpp/#define-debug-prefix>DEBUG_PREFIX</a></strong></td></tr></tbody></table><h2 id=detailed-description>Detailed Description <a href=#detailed-description class=anchor aria-hidden=true>#</a></h2><p><strong>Author</strong>:</p><ul><li>Abram Krislock (<a href=mailto:a.m.b.krislock@fys.uio.no>a.m.b.krislock@fys.uio.no</a>)</li><li>Aldo Saavedra</li><li>Andy Buckley</li><li>Chris Rogan (<a href=mailto:crogan@cern.ch>crogan@cern.ch</a>)</li><li>Pat Scott (<a href=mailto:p.scott@imperial.ac.uk>p.scott@imperial.ac.uk</a>)</li><li>Anders Kvellestad (<a href=mailto:anders.kvellestad@fys.uio.no>anders.kvellestad@fys.uio.no</a>)</li><li>Chris Chang</li></ul><p><strong>Date</strong>:</p><ul><li>2014 Aug</li><li>2015 May</li><li>2015 Jul</li><li>2018 Jan</li><li>2019 Jan</li><li>2017 March</li><li>2018 Jan</li><li>2018 May</li><li>2020 May</li><li>2020 Jun</li><li>2022 April</li></ul><p>ColliderBit LHC signal and likelihood functions.</p><hr><p>Authors (add name and date if you modify):</p><hr><h2 id=macros-documentation>Macros Documentation <a href=#macros-documentation class=anchor aria-hidden=true>#</a></h2><h3 id=define-debug-prefix>define DEBUG_PREFIX <a href=#define-debug-prefix class=anchor aria-hidden=true>#</a></h3><pre><code>#define DEBUG_PREFIX &quot;DEBUG: OMP thread &quot; &lt;&lt; omp_get_thread_num() &lt;&lt; &quot;:  &quot;
</code></pre><h2 id=source-code>Source code <a href=#source-code class=anchor aria-hidden=true>#</a></h2><pre><code>//   GAMBIT: Global and Modular BSM Inference Tool
//   *********************************************
///  \file
///
///  ColliderBit LHC signal and likelihood functions.
///
///  *********************************************
///
///  Authors (add name and date if you modify):
///
///  \author Abram Krislock
///          (a.m.b.krislock@fys.uio.no)
///
///  \author Aldo Saavedra
///
///  \author Andy Buckley
///
///  \author Chris Rogan
///          (crogan@cern.ch)
///  \date 2014 Aug
///  \date 2015 May
///
///  \author Pat Scott
///          (p.scott@imperial.ac.uk)
///  \date 2015 Jul
///  \date 2018 Jan
///  \date 2019 Jan
///
///  \author Anders Kvellestad
///          (anders.kvellestad@fys.uio.no)
///  \date   2017 March
///  \date   2018 Jan
///  \date   2018 May
///  \date   2020 May
///  \date   2020 Jun
///
///  \author Chris Chang
///  \date   2022 April
///
///  *********************************************

#include &lt;string&gt;
#include &lt;sstream&gt;

#include &quot;gambit/Elements/gambit_module_headers.hpp&quot;
#include &quot;gambit/ColliderBit/ColliderBit_rollcall.hpp&quot;
#include &quot;gambit/Utils/statistics.hpp&quot; 
#include &quot;gambit/Utils/util_macros.hpp&quot;
#include &quot;gambit/ColliderBit/Utils.hpp&quot;

#include &quot;multimin/multimin.hpp&quot;

#include &quot;gambit/Utils/begin_ignore_warnings_eigen.hpp&quot;
#include &quot;Eigen/Eigenvalues&quot;
#include &quot;gambit/Utils/end_ignore_warnings.hpp&quot;

#include &lt;gsl/gsl_sf_gamma.h&gt;

// #define COLLIDERBIT_DEBUG
#define DEBUG_PREFIX &quot;DEBUG: OMP thread &quot; &lt;&lt; omp_get_thread_num() &lt;&lt; &quot;:  &quot;

namespace Gambit
{

  namespace ColliderBit
  {


    /// Loop over all analyses and fill a map of predicted counts
    void calc_LHC_signals(map_str_dbl&amp; result)
    {
      using namespace Pipes::calc_LHC_signals;

      // Clear the result map
      result.clear();

      std::stringstream summary_line;
      summary_line &lt;&lt; &quot;LHC signals per SR: &quot;;

      // Loop over analyses and collect the predicted events into the map
      for (size_t analysis = 0; analysis &lt; Dep::AllAnalysisNumbers-&gt;size(); ++analysis)
      {
        // AnalysisData for this analysis
        const AnalysisData&amp; ana_data = *(Dep::AllAnalysisNumbers-&gt;at(analysis));

        summary_line &lt;&lt; ana_data.analysis_name &lt;&lt; &quot;: &quot;;

        // Loop over the signal regions inside the analysis, and save the predicted number of events for each.
        for (size_t SR = 0; SR &lt; ana_data.size(); ++SR)
        {
          // Save SR numbers and absolute uncertainties
          const SignalRegionData srData = ana_data[SR];
          const str key = ana_data.analysis_name + &quot;__&quot; + srData.sr_label + &quot;__i&quot; + std::to_string(SR) + &quot;__signal&quot;;
          result[key] = srData.n_sig_scaled;
          const double n_sig_scaled_err = srData.calc_n_sig_scaled_err();
          result[key + &quot;_uncert&quot;] = n_sig_scaled_err;

          summary_line &lt;&lt; srData.sr_label + &quot;__i&quot; + std::to_string(SR) &lt;&lt; &quot;:&quot; &lt;&lt; srData.n_sig_scaled &lt;&lt; &quot;+-&quot; &lt;&lt; n_sig_scaled_err &lt;&lt; &quot;, &quot;;
        }
      }
      logger() &lt;&lt; LogTags::debug &lt;&lt; summary_line.str() &lt;&lt; EOM;
    }




    /// Loglike objective-function wrapper to provide the signature for GSL multimin
    ///
    /// @note Doesn't return a full log-like: the factorial term is missing since it's expensive, fixed and cancels in DLLs
    void _gsl_calc_Analysis_MinusLogLike(const size_t n, const double* unit_nuisances_dbl,
                                         void* fixedparamspack, double* fval)
    {
      // Convert the array of doubles into an &quot;Eigen view&quot; of the nuisance params
      Eigen::Map&lt;const Eigen::ArrayXd&gt; unit_nuisances(&amp;unit_nuisances_dbl[0], n);

      // Convert the linearised array of doubles into &quot;Eigen views&quot; of the fixed params
      double *fixedparamspack_dbl = (double*) fixedparamspack;
      Eigen::Map&lt;const Eigen::VectorXd&gt; n_preds_nominal(&amp;fixedparamspack_dbl[0], n);
      Eigen::Map&lt;const Eigen::ArrayXd&gt; n_obss(&amp;fixedparamspack_dbl[n], n);
      Eigen::Map&lt;const Eigen::ArrayXd&gt; sqrtevals(&amp;fixedparamspack_dbl[2*n], n);
      Eigen::Map&lt;const Eigen::MatrixXd&gt; evecs(&amp;fixedparamspack_dbl[3*n], n, n);

      // Rotate rate deltas into the SR basis and shift by SR mean rates
      const Eigen::VectorXd n_preds = n_preds_nominal + evecs*(sqrtevals*unit_nuisances).matrix();

      // Calculate each SR's Poisson likelihood and add to composite likelihood calculation
      double loglike_tot = n * log(1/sqrt(2*M_PI)); //&lt; could also drop this, but it costs ~nothing
      for (size_t j = 0; j &lt; n; ++j)
      {
        // First the multivariate Gaussian bit (j = nuisance)
        const double pnorm_j = -pow(unit_nuisances(j), 2)/2.;
        loglike_tot += pnorm_j;

        // Then the Poisson bit (j = SR)
        /// @note We've dropped the log(n_obs!) terms, since they're expensive and cancel in computing DLL
        const double lambda_j = std::max(n_preds(j), 1e-3); //&lt; manually avoid &lt;= 0 rates

        // Also include the constant log(n_obs!) computation (via Stirling's approx), 
        // to avoid taking the difference of two very large numbers in the DLL.
        // @todo Just compute the logfact_n_obs term for each SR once per scan
        const double logfact_n_obs = (n_obss(j) &gt; 0) ? n_obss(j) * log(n_obss(j)) - n_obss(j) : 0;  

        const double loglike_j = n_obss(j)*log(lambda_j) - lambda_j - logfact_n_obs;

        loglike_tot += loglike_j;
      }

      // Output via argument (times -1 to return -LL for minimisation)
      *fval = -loglike_tot;
    }


    /// Loglike gradient-function wrapper to provide the signature for GSL multimin
    void _gsl_calc_Analysis_MinusLogLikeGrad(const size_t n, const double* unit_nuisances_dbl,
                                             void* fixedparamspack, double* fgrad)
    {
      // Convert the array of doubles into an &quot;Eigen view&quot; of the nuisance params
      Eigen::Map&lt;const Eigen::ArrayXd&gt; unit_nuisances(&amp;unit_nuisances_dbl[0], n);

      // Convert the linearised array of doubles into &quot;Eigen views&quot; of the fixed params
      double *fixedparamspack_dbl = (double*) fixedparamspack;
      Eigen::Map&lt;const Eigen::VectorXd&gt; n_preds_nominal(&amp;fixedparamspack_dbl[0], n);
      Eigen::Map&lt;const Eigen::ArrayXd&gt; n_obss(&amp;fixedparamspack_dbl[n], n);
      Eigen::Map&lt;const Eigen::ArrayXd&gt; sqrtevals(&amp;fixedparamspack_dbl[2*n], n);
      Eigen::Map&lt;const Eigen::MatrixXd&gt; evecs(&amp;fixedparamspack_dbl[3*n], n, n);

      // Rotate rate deltas into the SR basis and shift by SR mean rates
      const Eigen::VectorXd n_preds = n_preds_nominal + evecs*(sqrtevals*unit_nuisances).matrix();

      // Compute gradient elements
      for (int j = 0; j &lt; unit_nuisances.size(); ++j)
      {
        double llgrad = 0;
        for (int k = 0; k &lt; unit_nuisances.size(); ++k)
        {
          llgrad += (n_obss(k)/n_preds(k) - 1) * evecs(k,j);
        }
        llgrad = llgrad * sqrtevals(j) - unit_nuisances(j);
        // Output via argument (times -1 to return -dLL for minimisation)
        fgrad[j] = -llgrad;
      }
    }


    void _gsl_calc_Analysis_MinusLogLikeAndGrad(const size_t n, const double* unit_nuisances_dbl,
                                                void* fixedparamspack,
                                                double* fval, double* fgrad)
    {
      _gsl_calc_Analysis_MinusLogLike(n, unit_nuisances_dbl, fixedparamspack, fval);
      _gsl_calc_Analysis_MinusLogLikeGrad(n, unit_nuisances_dbl, fixedparamspack, fgrad);
    }


    std::vector&lt;double&gt; _gsl_mkpackedarray(const Eigen::ArrayXd&amp; n_preds,
                                           const Eigen::ArrayXd&amp; n_obss,
                                           const Eigen::ArrayXd&amp; sqrtevals,
                                           const Eigen::MatrixXd&amp; evecs)
    {
      const size_t nSR = n_obss.size();
      std::vector&lt;double&gt; fixeds(3*nSR + 2*nSR*nSR, 0.0);
      for (size_t i = 0; i &lt; nSR; ++i)
      {
        fixeds[0+i] = n_preds(i);
        fixeds[nSR+i] = n_obss(i);
        fixeds[2*nSR+i] = sqrtevals(i);
        for (size_t j = 0; j &lt; nSR; ++j)
        {
          fixeds[3*nSR+i*nSR+j] = evecs(j,i);
        }
      }

      return fixeds;
    }


    /// Return the best log likelihood
    /// @note Return value is missing the log(n_obs!) terms (n_SR of them) which cancel in LLR calculation
    /// @todo Pass in the cov, and compute the fixed evals, evecs, and corr matrix as fixed params in here? Via a helper function to reduce duplication
    double profile_loglike_cov(const Eigen::ArrayXd&amp; n_preds,
                               const Eigen::ArrayXd&amp; n_obss,
                               const Eigen::ArrayXd&amp; sqrtevals,
                               const Eigen::MatrixXd&amp; evecs)
    {
      // Number of signal regions
      const size_t nSR = n_obss.size();

      // Set initial guess for nuisances to zero
      std::vector&lt;double&gt; nuisances(nSR, 0.0);

      // // Set nuisances to an informed starting position
      // const Eigen::ArrayXd&amp; err_n_preds = (evecs*sqrtevals.matrix()).array(); //&lt; @todo CHECK
      // std::vector&lt;double&gt; nuisances(nSR, 0.0);
      // for (size_t j = 0; j &lt; nSR; ++j) 
      // {
      //   // Calculate the max-L starting position, ignoring correlations
      //   const double obs = n_obss(j);
      //   const double rate = n_preds(j);
      //   const double delta = err_n_preds(j);
      //   const double a = delta;
      //   const double b = rate + delta*delta;
      //   const double c = delta * (rate - obs);
      //   const double d = b*b - 4*a*c;
      //   const double sqrtd = (d &lt; 0) ? 0 : sqrt(d);
      //   if (sqrtd == 0)
      //   {
      //     nuisances[j] = -b / (2*a);
      //   }
      //   else
      //   {
      //     const double th0_a = (-b + sqrtd) / (2*a);
      //     const double th0_b = (-b - sqrtd) / (2*a);
      //     nuisances[j] = (fabs(th0_a) &lt; fabs(th0_b)) ? th0_a : th0_b;
      //   }
      // }


      // Optimiser parameters
      // Params: step1size, tol, maxiter, epsabs, simplex maxsize, method, verbosity
      // Methods:
      //  0: Fletcher-Reeves conjugate gradient
      //  1: Polak-Ribiere conjugate gradient
      //  2: Vector Broyden-Fletcher-Goldfarb-Shanno method
      //  3: Steepest descent algorithm
      //  4: Nelder-Mead simplex
      //  5: Vector Broyden-Fletcher-Goldfarb-Shanno method ver. 2
      //  6: Simplex algorithm of Nelder and Mead ver. 2
      //  7: Simplex algorithm of Nelder and Mead: random initialization
      using namespace Pipes::calc_LHC_LogLikes;
      static const double INITIAL_STEP = runOptions-&gt;getValueOrDef&lt;double&gt;(0.1, &quot;nuisance_prof_initstep&quot;);
      static const double CONV_TOL = runOptions-&gt;getValueOrDef&lt;double&gt;(0.01, &quot;nuisance_prof_convtol&quot;);
      static const unsigned MAXSTEPS = runOptions-&gt;getValueOrDef&lt;unsigned&gt;(10000, &quot;nuisance_prof_maxsteps&quot;);
      static const double CONV_ACC = runOptions-&gt;getValueOrDef&lt;double&gt;(0.01, &quot;nuisance_prof_convacc&quot;);
      static const double SIMPLEX_SIZE = runOptions-&gt;getValueOrDef&lt;double&gt;(1e-5, &quot;nuisance_prof_simplexsize&quot;);
      static const unsigned METHOD = runOptions-&gt;getValueOrDef&lt;unsigned&gt;(6, &quot;nuisance_prof_method&quot;);
      static const unsigned VERBOSITY = runOptions-&gt;getValueOrDef&lt;unsigned&gt;(0, &quot;nuisance_prof_verbosity&quot;);
      static const struct multimin::multimin_params oparams = {INITIAL_STEP, CONV_TOL, MAXSTEPS, CONV_ACC, SIMPLEX_SIZE, METHOD, VERBOSITY};

      // Convert the linearised array of doubles into &quot;Eigen views&quot; of the fixed params
      std::vector&lt;double&gt; fixeds = _gsl_mkpackedarray(n_preds, n_obss, sqrtevals, evecs);

      // Pass to the minimiser
      double minusbestll = 999;

      // Call minimizer with stderr temporarily silenced (due to gsl output)?
      static bool silence_multimin = runOptions-&gt;getValueOrDef&lt;bool&gt;(true, &quot;silence_multimin&quot;);

      // Call the minimizer
      if (silence_multimin)
      {
        CALL_WITH_SILENCED_STDERR(
          multimin::multimin(nSR, &amp;nuisances[0], &amp;minusbestll,
                   nullptr, nullptr, nullptr,
                   _gsl_calc_Analysis_MinusLogLike,
                   _gsl_calc_Analysis_MinusLogLikeGrad,
                   _gsl_calc_Analysis_MinusLogLikeAndGrad,
                   &amp;fixeds[0], oparams) 
        )
      }
      else
      {
        multimin::multimin(nSR, &amp;nuisances[0], &amp;minusbestll,
                 nullptr, nullptr, nullptr,
                 _gsl_calc_Analysis_MinusLogLike,
                 _gsl_calc_Analysis_MinusLogLikeGrad,
                 _gsl_calc_Analysis_MinusLogLikeAndGrad,
                 &amp;fixeds[0], oparams);
      }

      return -minusbestll;
    }


    double marg_loglike_nulike1sr(const Eigen::ArrayXd&amp; n_preds,
                                  const Eigen::ArrayXd&amp; n_obss,
                                  const Eigen::ArrayXd&amp; sqrtevals)
    {
      assert(n_preds.size() == 1);
      assert(n_obss.size() == 1);
      assert(sqrtevals.size() == 1);

      using namespace Pipes::calc_LHC_LogLikes;
      auto marginaliser = (*BEgroup::lnlike_marg_poisson == &quot;lnlike_marg_poisson_lognormal_error&quot;)
        ? BEreq::lnlike_marg_poisson_lognormal_error : BEreq::lnlike_marg_poisson_gaussian_error;

      // Setting bkg above zero to avoid nulike special cases
      const double sr_margll = marginaliser((int) n_obss(0), 0.001, n_preds(0), sqrtevals(0)/n_preds(0));
      return sr_margll;
    }


    double marg_loglike_cov(const Eigen::ArrayXd&amp; n_preds,
                            const Eigen::ArrayXd&amp; n_obss,
                            const Eigen::ArrayXd&amp; sqrtevals,
                            const Eigen::MatrixXd&amp; evecs)
    {
      // Number of signal regions
      const size_t nSR = n_obss.size();

      // Sample correlated SR rates from a rotated Gaussian defined by the covariance matrix and offset by the mean rates
      using namespace Pipes::calc_LHC_LogLikes;
      static const double CONVERGENCE_TOLERANCE_ABS = runOptions-&gt;getValueOrDef&lt;double&gt;(0.05, &quot;nuisance_marg_convthres_abs&quot;);
      static const double CONVERGENCE_TOLERANCE_REL = runOptions-&gt;getValueOrDef&lt;double&gt;(0.05, &quot;nuisance_marg_convthres_rel&quot;);
      static const size_t NSAMPLE_INPUT = runOptions-&gt;getValueOrDef&lt;size_t&gt;(100000, &quot;nuisance_marg_nsamples_start&quot;);
      static const bool   NULIKE1SR = runOptions-&gt;getValueOrDef&lt;bool&gt;(true, &quot;nuisance_marg_nulike1sr&quot;);

      // Optionally use nulike's more careful 1D marginalisation for one-SR cases
      if (NULIKE1SR &amp;&amp; nSR == 1) return marg_loglike_nulike1sr(n_preds, n_obss, sqrtevals);

      // Dynamic convergence control &amp; test has_and_variables
      size_t nsample = NSAMPLE_INPUT;
      bool first_iteration = true;
      double diff_abs = 9999;
      double diff_rel = 1;

      // Likelihood variables (note use of long double to guard against blow-up of L as opposed to log(L1/L0))
      long double ana_like_prev = 1;
      long double ana_like = 1;
      long double lsum_prev = 0;

      // Sampler for unit-normal nuisances
      std::normal_distribution&lt;double&gt; unitnormdbn(0,1);

      // Log factorial of observed number of events.
      // Currently use the ln(Gamma(x)) function gsl_sf_lngamma from GSL. (Need continuous function.)
      // We may want to switch to using Stirling's approximation: ln(n!) ~ n*ln(n) - n
      Eigen::ArrayXd logfact_n_obss(nSR);
      for (size_t j = 0; j &lt; nSR; ++j)
        logfact_n_obss(j) = gsl_sf_lngamma(n_obss(j) + 1);

      // Check absolute difference between independent has_and_estimates
      /// @todo Should also implement a check of relative difference
      while ((diff_abs &gt; CONVERGENCE_TOLERANCE_ABS &amp;&amp; diff_rel &gt; CONVERGENCE_TOLERANCE_REL) || 1.0/sqrt(nsample) &gt; CONVERGENCE_TOLERANCE_ABS)
      {
        long double lsum = 0;

        /// @note How to correct negative rates? Discard (scales badly), set to
        /// epsilon (= discontinuous &amp; unphysical pdf), transform to log-space
        /// (distorts the pdf quite badly), or something else (skew term)?
        /// We're using the &quot;set to epsilon&quot; version for now.
        /// Ben: I would vote for 'discard'. It can't be that inefficient, surely?
        /// Andy: For a lot of signal regions, the probability of none having a negative sample is Prod_SR p(non-negative)_SR... which *can* get bad.

        #pragma omp parallel
        {
          // Sample correlated SR rates from a rotated Gaussian defined by the covariance matrix and offset by the mean rates
          double lsum_private  = 0;
          #pragma omp for nowait
          for (size_t i = 0; i &lt; nsample; ++i)
          {
            Eigen::VectorXd norm_samples(nSR);
            for (size_t j = 0; j &lt; nSR; ++j)
              norm_samples(j) = sqrtevals(j) * unitnormdbn(Random::rng());

            // Rotate rate deltas into the SR basis and shift by SR mean rates
            const Eigen::VectorXd n_pred_samples  = n_preds + (evecs*norm_samples).array();

            // Calculate Poisson likelihood and add to composite likelihood calculation
            double combined_loglike = 0;
            for (size_t j = 0; j &lt; nSR; ++j)
            {
              const double lambda_j = std::max(n_pred_samples(j), 1e-3); //&lt; manually avoid &lt;= 0 rates
              const double loglike_j  = n_obss(j)*log(lambda_j) - lambda_j - logfact_n_obss(j);
              combined_loglike += loglike_j;
            }
            // Add combined likelihood to running sums (to later calculate averages)
            lsum_private += exp(combined_loglike);
          }

          #pragma omp critical
          {
            lsum  += lsum_private;
          }
        } // End omp parallel

        // Compare convergence to previous independent batch
        if (first_iteration)  // The first round must be generated twice
        {
          lsum_prev = lsum;
          first_iteration = false;
        }
        else
        {
          ana_like_prev = lsum_prev / (double)nsample;
          ana_like = lsum / (double)nsample;
          diff_abs = fabs(ana_like_prev - ana_like);
          diff_rel = diff_abs/ana_like;

          // Update variables
          lsum_prev += lsum;  // Aggregate result. This doubles the effective batch size for lsum_prev.
          nsample *=2;  // This ensures that the next batch for lsum is as big as the current batch size for lsum_prev, so they can be compared directly.
        }

        #ifdef COLLIDERBIT_DEBUG
        cout &lt;&lt; DEBUG_PREFIX
             &lt;&lt; &quot;diff_rel: &quot; &lt;&lt; diff_rel &lt;&lt; endl
             &lt;&lt; &quot;   diff_abs: &quot; &lt;&lt; diff_abs &lt;&lt; endl
             &lt;&lt; &quot;   logl: &quot; &lt;&lt; log(ana_like) &lt;&lt; endl;
        cout &lt;&lt; DEBUG_PREFIX &lt;&lt; &quot;nsample for the next iteration is: &quot; &lt;&lt; nsample &lt;&lt; endl;
        cout &lt;&lt; DEBUG_PREFIX &lt;&lt; endl;
        #endif
      }
      // End convergence while-loop

      // Combine the independent estimates ana_like and ana_like_prev.
      // Use equal weights since the estimates are based on equal batch sizes.
      ana_like = 0.5*(ana_like + ana_like_prev);
      const double ana_margll = log(ana_like);
      #ifdef COLLIDERBIT_DEBUG
      cout &lt;&lt; DEBUG_PREFIX &lt;&lt; &quot;Combined estimate: ana_loglike: &quot; &lt;&lt; ana_margll &lt;&lt; &quot;   (based on 2*nsample=&quot; &lt;&lt; 2*nsample &lt;&lt; &quot; samples)&quot; &lt;&lt; endl;
      #endif

      return ana_margll;
    }


    /// Helper function called by fill_analysis_loglikes below. It's used to get the 
    /// loglike(s) for ATLAS analyses for which we have the ATLAS Full Likelihood information.
    void fill_analysis_loglikes_full(const AnalysisData&amp; ana_data, 
                                AnalysisLogLikes&amp; ana_loglikes,
                                bool (*FullLikes_FileExists)(const str&amp;),
                                int (*FullLikes_ReadIn)(const str&amp;, const str&amp;),
                                double (*FullLikes_Evaluate)(std::map&lt;str,double&gt;&amp;,const str&amp;),
                                const std::string alt_loglike_key = &quot;&quot;)
    {
      // Are we filling the standard loglike or an alternative one?
      bool fill_alt_loglike = false;
      if (!alt_loglike_key.empty()) fill_alt_loglike = true;

      // Get number of signal regions
      const size_t nSR = ana_data.size();

      // Get the analysis name
      const std::string ana_name = ana_data.analysis_name;

      // Check if analysis is to use ATLAS Full Likelihood backend
      // If the json hasn't been read in, read it in 
      bool FullLikes_jsonread = (*FullLikes_FileExists)(ana_name); 
      if (!FullLikes_jsonread)
      {
        if ((*FullLikes_ReadIn)(ana_name,ana_data.bkgjson_path) != 0)
        {
          ColliderBit_error().raise(LOCAL_INFO,&quot;Error: ATLAS FullLikes Failed to read in BKG JSON file for analysis: &quot; + ana_name);
        }
      }

      // Delta log-likelihood variable
      double dll = NAN;

      // Work out the total (delta) log likelihood for this analysis, by passing in the signal predictions
      // in a map&lt;str,double&gt; to the ATLAS_FullLikes backend.
      std::map&lt;str,double&gt; SRsignal;

      for (size_t SR = 0; SR &lt; nSR; ++SR)
      {
        str SRName = ana_data[SR].sr_label;
        SRsignal[SRName] = ana_data[SR].n_sig_scaled;
      }

      dll = (*FullLikes_Evaluate)(SRsignal,ana_name);

      // Write result to the ana_loglikes reference
      ana_loglikes.combination_sr_label = &quot;all&quot;;
      ana_loglikes.combination_sr_index = -1;
      if (fill_alt_loglike)
      {
        ana_loglikes.alt_combination_loglikes.at(alt_loglike_key) = dll;
      }
      else
      {
        ana_loglikes.combination_loglike = dll;
      }
    }
      
    /// Helper function called by calc_LHC_LogLikes to compute the loglike(s) for a given analysis.
    void fill_analysis_loglikes(const AnalysisData&amp; ana_data, 
                                AnalysisLogLikes&amp; ana_loglikes,
                                bool use_marg,
                                bool has_and_use_covar,
                                bool combine_nocovar_SRs,
                                bool has_and_use_fulllikes,
                                bool (*FullLikes_FileExists)(const str&amp;),
                                int (*FullLikes_ReadIn)(const str&amp;, const str&amp;),
                                double (*FullLikes_Evaluate)(std::map&lt;str,double&gt;&amp;,const str&amp;),
                                const std::string alt_loglike_key = &quot;&quot;)
    {
      // Are we filling the standard loglike or an alternative one?
      bool fill_alt_loglike = false;
      if (!alt_loglike_key.empty()) fill_alt_loglike = true;

      // Choose the profiling/marginalising function according to the option
      auto marg_prof_fn = use_marg ? marg_loglike_cov : profile_loglike_cov;

      // Get number of signal regions
      const size_t nSR = ana_data.size();

      // Get the analysis name
      const std::string ana_name = ana_data.analysis_name;

      // Delta log-likelihood variable
      double dll = NAN;

      // Work out the total (delta) log likelihood for this analysis, with correlations as available/instructed
      if (has_and_use_fulllikes)
      {
        fill_analysis_loglikes_full(ana_data,ana_loglikes,FullLikes_FileExists,FullLikes_ReadIn,FullLikes_Evaluate,alt_loglike_key);
      }
      else if (has_and_use_covar)  // Use SR covariance info?
      {

        // Check that we are indeed using the right function to compute the loglikes
        assert (ana_data.srcov.rows() &gt; 0);

        // Construct vectors of SR numbers
        /// @todo Unify this for both cov and no-cov, feeding in one-element Eigen blocks as Ref&lt;&gt;s for the latter?
        Eigen::ArrayXd n_obs(nSR); // logfact_n_obs(nSR);
        Eigen::ArrayXd n_pred_b(nSR);
        Eigen::ArrayXd n_pred_sb(nSR);
        Eigen::ArrayXd abs_unc_s(nSR);
        for (size_t SR = 0; SR &lt; nSR; ++SR)
        {
          const SignalRegionData&amp; srData = ana_data[SR];

          // Actual observed number of events
          n_obs(SR) = srData.n_obs;

          // Log factorial of observed number of events.
          // Currently use the ln(Gamma(x)) function gsl_sf_lngamma from GSL. (Need continuous function.)
          // We may want to switch to using Stirling's approximation: ln(n!) ~ n*ln(n) - n
          //logfact_n_obs(SR) = gsl_sf_lngamma(n_obs(SR) + 1.);

          // A contribution to the predicted number of events that is not known exactly
          n_pred_b(SR) = std::max(srData.n_bkg, 0.001); // &lt;-- Avoid trouble with b==0
          n_pred_sb(SR) = srData.n_sig_scaled + srData.n_bkg;

          // Absolute errors for n_predicted_uncertain_*
          abs_unc_s(SR) = srData.calc_n_sig_scaled_err();
        }

        // Diagonalise the background-only covariance matrix, extracting the correlation and rotation matrices
        /// @todo Compute the background-only covariance decomposition and likelihood only once
        const Eigen::MatrixXd&amp; srcov_b = ana_data.srcov;
        Eigen::MatrixXd srcorr_b = srcov_b; // start with cov, then make corr
        for (size_t SR = 0; SR &lt; nSR; ++SR)
        {
          const double diagsd = sqrt(srcov_b(SR,SR));
          srcorr_b.row(SR) /= diagsd;
          srcorr_b.col(SR) /= diagsd;
        }
        const Eigen::SelfAdjointEigenSolver&lt;Eigen::MatrixXd&gt; eig_b(ana_data.srcov);
        const Eigen::ArrayXd Eb = eig_b.eigenvalues();
        const Eigen::ArrayXd sqrtEb = Eb.sqrt();
        const Eigen::MatrixXd Vb = eig_b.eigenvectors();

        // Construct and diagonalise the s+b covariance matrix, adding the diagonal signal uncertainties in quadrature
        const Eigen::MatrixXd srcov_s = abs_unc_s.array().square().matrix().asDiagonal();
        const Eigen::MatrixXd srcov_sb = srcov_b + srcov_s;
        Eigen::MatrixXd srcorr_sb = srcov_sb;
        for (size_t SR = 0; SR &lt; nSR; ++SR)
        {
          const double diagsd = sqrt(srcov_sb(SR,SR));
          srcorr_sb.row(SR) /= diagsd;
          srcorr_sb.col(SR) /= diagsd;
        }
        const Eigen::SelfAdjointEigenSolver&lt;Eigen::MatrixXd&gt; eig_sb(srcov_sb);
        const Eigen::ArrayXd Esb = eig_sb.eigenvalues();
        const Eigen::ArrayXd sqrtEsb = Esb.sqrt();
        const Eigen::MatrixXd Vsb = eig_sb.eigenvectors();

        // Compute the single, correlated analysis-level DLL as the difference of s+b and b (partial) LLs
        /// @todo Only compute this once per run
        const double ll_b = marg_prof_fn(n_pred_b, n_obs, sqrtEb, Vb);
        const double ll_sb = marg_prof_fn(n_pred_sb, n_obs, sqrtEsb, Vsb);
        dll = ll_sb - ll_b;

        // Write result to the ana_loglikes reference
        ana_loglikes.combination_sr_label = &quot;all&quot;;
        ana_loglikes.combination_sr_index = -1;
        if (fill_alt_loglike)
        {
          ana_loglikes.alt_combination_loglikes.at(alt_loglike_key) = dll;
        }
        else
        {
          ana_loglikes.combination_loglike = dll;
        }
      }
      else // No SR covariance info (or user chose not to use this)
      { 

        // We either take the result from the SR *expected* to be most
        // constraining under the s=0 assumption (default), or naively combine
        // the loglikes for all SRs (if combine_SRs_without_covariances=true).
        #ifdef COLLIDERBIT_DEBUG
        cout &lt;&lt; DEBUG_PREFIX &lt;&lt; &quot;calc_LHC_LogLikes: Analysis &quot; &lt;&lt; analysis &lt;&lt; &quot; has no covariance matrix: computing single best-expected loglike.&quot; &lt;&lt; endl;
        #endif

        double bestexp_dll_exp = 0, bestexp_dll_obs = NAN;
        str bestexp_sr_label;
        int bestexp_sr_index;
        double nocovar_srsum_dll_obs = 0;

        for (size_t SR = 0; SR &lt; nSR; ++SR)
        {
          const SignalRegionData&amp; srData = ana_data[SR];

          // Shortcut: If n_sig_MC == 0, we know the delta log-likelihood is 0.
          if(srData.n_sig_MC == 0)
          {
            // Store (obs) dll for this SR
            if (fill_alt_loglike)
            {
              ana_loglikes.alt_sr_loglikes.at(alt_loglike_key).at(SR) = 0.0;
            }
            else
            {
              ana_loglikes.sr_loglikes.at(SR) = 0.0;
            }

            // Update the running best-expected-exclusion detail
            if (0.0 &lt; bestexp_dll_exp || SR == 0)
            {
              bestexp_dll_exp = 0.0;
              bestexp_dll_obs = 0.0;
              bestexp_sr_label = srData.sr_label;
              bestexp_sr_index = SR;
            }

            // Skip to next SR
            continue;
          }

          // A contribution to the predicted number of events that is not known exactly
          const double n_pred_b = std::max(srData.n_bkg, 0.001); // &lt;-- Avoid trouble with b==0
          const double n_pred_sb = n_pred_b + srData.n_sig_scaled;

          // Actual observed number of events and predicted background, as integers cf. Poisson stats
          const double n_obs = round(srData.n_obs);
          const double n_pred_b_int = round(n_pred_b);

          // Absolute errors for n_predicted_uncertain_*
          const double abs_uncertainty_b = std::max(srData.n_bkg_err, 0.001); // &lt;-- Avoid trouble with b_err==0
          const double abs_uncertainty_sb = std::max(srData.calc_n_sigbkg_err(), 0.001); // &lt;-- Avoid trouble with sb_err==0

          // Construct dummy 1-element Eigen objects for passing to the general likelihood calculator
          /// @todo Use newer (?) one-step Eigen constructors for (const) single-element arrays
          Eigen::ArrayXd n_obss(1);        n_obss(0) = n_obs;
          Eigen::ArrayXd n_preds_b_int(1); n_preds_b_int(0) = n_pred_b_int;
          Eigen::ArrayXd n_preds_b(1);     n_preds_b(0) = n_pred_b;
          Eigen::ArrayXd n_preds_sb(1);    n_preds_sb(0) = n_pred_sb;
          Eigen::ArrayXd sqrtevals_b(1);   sqrtevals_b(0) = abs_uncertainty_b;
          Eigen::ArrayXd sqrtevals_sb(1);  sqrtevals_sb(0) = abs_uncertainty_sb;
          Eigen::MatrixXd dummy(1,1); dummy(0,0) = 1.0;

          // Compute this SR's DLLs as the differences of s+b and b (partial) LLs
          /// @todo Only compute this once per run
          const double ll_b_exp = marg_prof_fn(n_preds_b, n_preds_b_int, sqrtevals_b, dummy);
          /// @todo Only compute this once per run
          const double ll_b_obs = marg_prof_fn(n_preds_b, n_obss, sqrtevals_b, dummy);
          const double ll_sb_exp = marg_prof_fn(n_preds_sb, n_preds_b_int, sqrtevals_sb, dummy);
          const double ll_sb_obs = marg_prof_fn(n_preds_sb, n_obss, sqrtevals_sb, dummy);
          const double dll_exp = ll_sb_exp - ll_b_exp;
          const double dll_obs = ll_sb_obs - ll_b_obs;

          // Check for problems
          if (Utils::isnan(ll_b_exp))
          {
            std::stringstream msg;
            msg &lt;&lt; &quot;Computation of ll_b_exp for signal region &quot; &lt;&lt; srData.sr_label &lt;&lt; &quot; in analysis &quot; &lt;&lt; ana_name &lt;&lt; &quot; returned NaN&quot; &lt;&lt; endl;
            invalid_point().raise(msg.str());
          }
          if (Utils::isnan(ll_b_obs))
          {
            std::stringstream msg;
            msg &lt;&lt; &quot;Computation of ll_b_obs for signal region &quot; &lt;&lt; srData.sr_label &lt;&lt; &quot; in analysis &quot; &lt;&lt; ana_name &lt;&lt; &quot; returned NaN&quot; &lt;&lt; endl;
            invalid_point().raise(msg.str());
          }
          if (Utils::isnan(ll_sb_exp))
          {
            std::stringstream msg;
            msg &lt;&lt; &quot;Computation of ll_sb_exp for signal region &quot; &lt;&lt; srData.sr_label &lt;&lt; &quot; in analysis &quot; &lt;&lt; ana_name &lt;&lt; &quot; returned NaN&quot; &lt;&lt; endl;
            invalid_point().raise(msg.str());
          }
          if (Utils::isnan(ll_sb_obs))
          {
            std::stringstream msg;
            msg &lt;&lt; &quot;Computation of ll_sb_obs for signal region &quot; &lt;&lt; srData.sr_label &lt;&lt; &quot; in analysis &quot; &lt;&lt; ana_name &lt;&lt; &quot; returned NaN&quot; &lt;&lt; endl;
            invalid_point().raise(msg.str());
          }

          // Update the running best-expected-exclusion detail
          if (dll_exp &lt; bestexp_dll_exp || SR == 0)
          {
            bestexp_dll_exp = dll_exp;
            bestexp_dll_obs = dll_obs;
            bestexp_sr_label = srData.sr_label;
            bestexp_sr_index = SR;
            #ifdef COLLIDERBIT_DEBUG
            cout &lt;&lt; DEBUG_PREFIX &lt;&lt; &quot;Setting bestexp_sr_label to: &quot; &lt;&lt; bestexp_sr_label &lt;&lt; &quot;, bestexp_dll_exp = &quot; &lt;&lt; bestexp_dll_exp &lt;&lt; &quot;, bestexp_dll_obs = &quot; &lt;&lt; bestexp_dll_obs &lt;&lt; endl;
            #endif
          }

          // Store (obs) dll for this SR
          if (fill_alt_loglike)
          {
            ana_loglikes.alt_sr_loglikes.at(alt_loglike_key).at(SR) = dll_obs;
          }
          else
          {
            ana_loglikes.sr_loglikes.at(SR) = dll_obs;
          }

          // Also add the obs loglike to the no-correlations sum over SRs
          nocovar_srsum_dll_obs += dll_obs;

          #ifdef COLLIDERBIT_DEBUG
          cout &lt;&lt; DEBUG_PREFIX &lt;&lt; ana_name &lt;&lt; &quot;, &quot; &lt;&lt; srData.sr_label &lt;&lt; &quot;,  llsb_exp-llb_exp = &quot; &lt;&lt; dll_exp &lt;&lt; &quot;,  llsb_obs-llb_obs= &quot; &lt;&lt; dll_obs &lt;&lt; endl;
          #endif

        }

        // Set this analysis' total obs DLL to that from the best-expected SR
        dll = bestexp_dll_obs;
        // Or should we use the naive sum of SR loglikes (without correlations) instead?
        if (combine_nocovar_SRs)
        {
          dll = nocovar_srsum_dll_obs;
        }

        // Write combined loglike to the ana_loglikes reference
        if (fill_alt_loglike)
        {
          ana_loglikes.alt_combination_loglikes.at(alt_loglike_key) = dll;
        }
        else
        {
          ana_loglikes.combination_loglike = dll;
          ana_loglikes.combination_sr_label = bestexp_sr_label;
          ana_loglikes.combination_sr_index = bestexp_sr_index;
          #ifdef COLLIDERBIT_DEBUG
          cout &lt;&lt; DEBUG_PREFIX &lt;&lt; &quot;calc_LHC_LogLikes: &quot; &lt;&lt; ana_name &lt;&lt; &quot;_&quot; &lt;&lt; bestexp_sr_label &lt;&lt; &quot;_LogLike : &quot; &lt;&lt; dll &lt;&lt; endl;
          #endif
        }

      } // end large cov/no-cov if-else block

      // Check for problems with the result
      bool check_failed = false;  
      std::string failed_at_label = &quot;&quot;;

      // - First check combined loglike
      double check_loglike = 0;
      if (fill_alt_loglike)
      {
        check_loglike = ana_loglikes.alt_combination_loglikes.at(alt_loglike_key);
      }
      else
      {
        check_loglike = ana_loglikes.combination_loglike;
      } 
      if (Utils::isnan(check_loglike))
      {
        check_failed = true;
        failed_at_label = &quot;combined&quot;;
      }

      // Then check individual SR loglikes
      if (!check_failed)
      {
        for (size_t SR = 0; SR &lt; nSR; ++SR)
        {
          if (fill_alt_loglike)
          {
            check_loglike = ana_loglikes.alt_sr_loglikes.at(alt_loglike_key).at(SR);
          }
          else
          {
            check_loglike = ana_loglikes.sr_loglikes.at(SR);
          } 
          if (Utils::isnan(check_loglike))
          {
            check_failed = true;
            failed_at_label = ana_loglikes.sr_labels.at(SR);
            break;
          }
        }
      }

      if (check_failed)
      {
        std::stringstream msg;
        msg &lt;&lt; &quot;Computation of &quot;;
        if (fill_alt_loglike) msg &lt;&lt; alt_loglike_key &lt;&lt; &quot; &quot;;
        msg &lt;&lt; &quot;loglike for signal region '&quot; &lt;&lt; failed_at_label &lt;&lt; &quot;' in analysis &quot; &lt;&lt; ana_name &lt;&lt; &quot; returned NaN.&quot; &lt;&lt; endl;
        msg &lt;&lt; &quot;Will now print some signal region data for this analysis:&quot; &lt;&lt; endl;
        for (size_t i = 0; i &lt; nSR; ++i)
        {
          const SignalRegionData&amp; srData = ana_data[i];
          msg &lt;&lt; srData.sr_label
              &lt;&lt; &quot;,  n_bkg = &quot; &lt;&lt; srData.n_bkg
              &lt;&lt; &quot;,  n_bkg_err = &quot; &lt;&lt; srData.n_bkg_err
              &lt;&lt; &quot;,  n_obs = &quot; &lt;&lt; srData.n_obs
              &lt;&lt; &quot;,  n_sig_scaled = &quot; &lt;&lt; srData.n_sig_scaled
              &lt;&lt; &quot;,  n_sig_MC = &quot; &lt;&lt; srData.n_sig_MC
              &lt;&lt; &quot;,  n_sig_MC_sys = &quot; &lt;&lt; srData.n_sig_MC_sys
              &lt;&lt; endl;
        }
        invalid_point().raise(msg.str());
      }
    }



    /// Loop over all analyses and fill a map of AnalysisLogLikes objects
    void calc_LHC_LogLikes_common(map_str_AnalysisLogLikes&amp; result,
                                  bool use_fulllikes, 
                                  AnalysisDataPointers&amp; ana,
                                  const Options&amp; runOptions,
                                  bool skip_calc,
                                  bool (*FullLikes_FileExists)(const str&amp;),
                                  int (*FullLikes_ReadIn)(const str&amp;, const str&amp;),
                                  double (*FullLikes_Evaluate)(std::map&lt;str,double&gt;&amp;,const str&amp;))
    {
      static bool first = true;

      // Use covariance matrices if available?
      static const bool use_covar = runOptions.getValueOrDef&lt;bool&gt;(true, &quot;use_covariances&quot;);
      // Use the naive sum of SR loglikes when not using covariances?
      static const bool combine_nocovar_SRs = runOptions.getValueOrDef&lt;bool&gt;(false, &quot;combine_SRs_without_covariances&quot;);
      // Use marginalisation rather than profiling (probably less stable)?
      static const bool use_marg = runOptions.getValueOrDef&lt;bool&gt;(false, &quot;use_marginalising&quot;);
      // Calculate various alternative loglikes?
      static const bool calc_noerr_loglikes = runOptions.getValueOrDef&lt;bool&gt;(false, &quot;calc_noerr_loglikes&quot;);
      static const bool calc_expected_loglikes = runOptions.getValueOrDef&lt;bool&gt;(false, &quot;calc_expected_loglikes&quot;);
      static const bool calc_expected_noerr_loglikes = runOptions.getValueOrDef&lt;bool&gt;(false, &quot;calc_expected_noerr_loglikes&quot;);
      static const bool calc_scaledsignal_loglikes = runOptions.getValueOrDef&lt;bool&gt;(false, &quot;calc_scaledsignal_loglikes&quot;);
      static const double signal_scalefactor = runOptions.getValueOrDef&lt;double&gt;(1.0, &quot;signal_scalefactor&quot;);

      // Create a list of keys for the alternative loglikes that are activated
      static std::vector&lt;std::string&gt; alt_loglike_keys;
      if (first)
      {
        if (calc_noerr_loglikes) alt_loglike_keys.push_back(&quot;noerr&quot;);
        if (calc_expected_loglikes) alt_loglike_keys.push_back(&quot;expected&quot;);
        if (calc_expected_noerr_loglikes) alt_loglike_keys.push_back(&quot;expected_noerr&quot;);
        if (calc_scaledsignal_loglikes) alt_loglike_keys.push_back(&quot;scaledsignal&quot;);
        first = false;
      }

      // Clear the result map
      result.clear();

      // Loop over analyses in Dep::AllAnalysisNumbers
      // Main loop over all analyses to compute DLL = LL_sb - LL_b
      for (size_t analysis = 0; analysis &lt; ana.size(); ++analysis)
      {
        // AnalysisData for this analysis
        const AnalysisData&amp; ana_data = *(ana.at(analysis));
        const std::string ana_name = ana_data.analysis_name;
        const size_t nSR = ana_data.size();
        const bool has_covar = ana_data.srcov.rows() &gt; 0;
        const bool has_fulllikes = ana_data.hasFullLikes();
        
        // Initialize the AnalysisLogLikes instance in the result map
        result[ana_name].initialize(ana_data, alt_loglike_keys);

        // We will access this AnalysisLogLikes instance via a shorthand reference 'ana_loglikes'
        AnalysisLogLikes&amp; ana_loglikes = result[ana_name];

        #ifdef COLLIDERBIT_DEBUG
        std::streamsize stream_precision = cout.precision();  // get current precision
        cout.precision(2);  // set precision
        cout &lt;&lt; DEBUG_PREFIX &lt;&lt; &quot;calc_LHC_LogLikes: &quot; &lt;&lt; &quot;Will print content of &quot; &lt;&lt; ana_name &lt;&lt; &quot; signal regions:&quot; &lt;&lt; endl;
        for (size_t SR = 0; SR &lt; ana_data.size(); ++SR)
        {
          const SignalRegionData&amp; srData = ana_data[SR];
          cout &lt;&lt; std::fixed &lt;&lt; DEBUG_PREFIX
                                 &lt;&lt; &quot;calc_LHC_LogLikes: &quot; &lt;&lt; ana_name
                                 &lt;&lt; &quot;, &quot; &lt;&lt; srData.sr_label
                                 &lt;&lt; &quot;,  n_b = &quot; &lt;&lt; srData.n_bkg &lt;&lt; &quot; +/- &quot; &lt;&lt; srData.n_bkg_err
                                 &lt;&lt; &quot;,  n_obs = &quot; &lt;&lt; srData.n_obs
                                 &lt;&lt; &quot;,  excess = &quot; &lt;&lt; srData.n_obs - srData.n_bkg &lt;&lt; &quot; +/- &quot; &lt;&lt; srData.n_bkg_err
                                 &lt;&lt; &quot;,  n_s = &quot; &lt;&lt; srData.n_sig_scaled
                                 &lt;&lt; &quot;,  (excess-n_s) = &quot; &lt;&lt; (srData.n_obs-srData.n_bkg) - srData.n_sig_scaled &lt;&lt; &quot; +/- &quot; &lt;&lt; srData.n_bkg_err
                                 &lt;&lt; &quot;,  n_s_MC = &quot; &lt;&lt; srData.n_sig_MC
                                 &lt;&lt; endl;
        }
        cout.precision(stream_precision); // restore previous precision
        #endif

        // Shortcut #1
        if (skip_calc)
        {
          // If this is an analysis with covariance info, only add a single 0-entry in the map
          if (use_covar &amp;&amp; has_covar)
          {
            ana_loglikes.set_no_signal_result_combination(&quot;none&quot;, -1);
          }
          // If this is an analysis without covariance info, add 0-entries for all SRs plus
          // one for the combined LogLike
          else
          {
            ana_loglikes.set_no_signal_result_all_SRs(&quot;none&quot;, -1);
          }

          #ifdef COLLIDERBIT_DEBUG
          cout &lt;&lt; DEBUG_PREFIX &lt;&lt; &quot;calc_LHC_LogLikes: &quot; &lt;&lt; ana_name &lt;&lt; &quot;_LogLike : &quot; &lt;&lt; 0.0 &lt;&lt; &quot; (No events predicted / successfully generated. Skipped full calculation.)&quot; &lt;&lt; endl;
          #endif

          // Continue to next analysis
          continue;
        }

        // Shortcut #2
        //
        // If all SRs have 0 signal prediction, we know the delta log-likelihood is 0.
        bool all_zero_signal = true;
        for (size_t SR = 0; SR &lt; nSR; ++SR)
        {
          if (ana_data[SR].n_sig_MC != 0)
          {
            all_zero_signal = false;
            break;
          }
        }
        if (all_zero_signal)
        {
          // Store result
          if (use_covar &amp;&amp; has_covar)
          {
            ana_loglikes.set_no_signal_result_combination(&quot;all&quot;, -1);
          }
          else
          {
            ana_loglikes.set_no_signal_result_all_SRs(&quot;all&quot;, -1);
          }

          #ifdef COLLIDERBIT_DEBUG
          cout &lt;&lt; DEBUG_PREFIX &lt;&lt; &quot;calc_LHC_LogLikes: &quot; &lt;&lt; ana_name &lt;&lt; &quot;_LogLike : &quot; &lt;&lt; 0.0 &lt;&lt; &quot; (No signal predicted. Skipped full calculation.)&quot; &lt;&lt; endl;
          #endif

          // Continue to next analysis
          continue;
        }

        // Now perform the actual loglikes compuations for this analysis
        // 
        // First do standard loglike calculation
        fill_analysis_loglikes(ana_data, ana_loglikes, use_marg, use_covar &amp;&amp; has_covar, combine_nocovar_SRs, has_fulllikes &amp;&amp; use_fulllikes,FullLikes_FileExists,FullLikes_ReadIn,FullLikes_Evaluate);

        // Then do alternative loglike calculations:
        if (calc_noerr_loglikes)
        {
          // Get a copy of the analysis data that we can modify
          AnalysisData ana_data_mod(ana_data);
          // Set the signal MC error to 0 for all signal regions
          for (size_t SR = 0; SR &lt; nSR; ++SR)
          {
            ana_data_mod[SR].n_sig_MC_stat = 0.;
          }
          fill_analysis_loglikes(ana_data_mod, ana_loglikes, use_marg, use_covar &amp;&amp; has_covar, combine_nocovar_SRs, has_fulllikes &amp;&amp;  use_fulllikes,FullLikes_FileExists,FullLikes_ReadIn,FullLikes_Evaluate,&quot;noerr&quot;);
        }
        if (calc_expected_loglikes)
        {
          // Get a copy of the analysis data that we can modify
          AnalysisData ana_data_mod(ana_data);
          // Set the observed count = expected background count
          for (size_t SR = 0; SR &lt; nSR; ++SR)
          {
            ana_data_mod[SR].n_obs = ana_data_mod[SR].n_bkg;
          }
          fill_analysis_loglikes(ana_data_mod, ana_loglikes, use_marg, use_covar &amp;&amp; has_covar, combine_nocovar_SRs, has_fulllikes &amp;&amp; use_fulllikes,FullLikes_FileExists,FullLikes_ReadIn,FullLikes_Evaluate, &quot;expected&quot;);
        }
        if (calc_expected_noerr_loglikes)
        {
          // Get a copy of the analysis data that we can modify
          AnalysisData ana_data_mod(ana_data);
          // Set the observed count = expected background count, 
          // and set the signal MC error to 0 for all signal regions
          for (size_t SR = 0; SR &lt; nSR; ++SR)
          {
            ana_data_mod[SR].n_obs = ana_data_mod[SR].n_bkg;
            ana_data_mod[SR].n_sig_MC_stat = 0.;
          }
          fill_analysis_loglikes(ana_data_mod, ana_loglikes, use_marg, use_covar &amp;&amp; has_covar, combine_nocovar_SRs, has_fulllikes &amp;&amp; use_fulllikes,FullLikes_FileExists,FullLikes_ReadIn,FullLikes_Evaluate, &quot;expected_noerr&quot;);
        }
        if (calc_scaledsignal_loglikes)
        {
          // Get a copy of the analysis data that we can modify
          AnalysisData ana_data_mod(ana_data);
          // Scale the signal all signal regions
          for (size_t SR = 0; SR &lt; nSR; ++SR)
          {
            ana_data_mod[SR].n_sig_scaled *= signal_scalefactor;
          }
          fill_analysis_loglikes(ana_data_mod, ana_loglikes, use_marg, use_covar &amp;&amp; has_covar, combine_nocovar_SRs, has_fulllikes &amp;&amp; use_fulllikes,FullLikes_FileExists,FullLikes_ReadIn,FullLikes_Evaluate, &quot;scaledsignal&quot;);
        }

      } // end analysis loop
    }


    /// Loop over all analyses and fill a map of AnalysisLogLikes objects
    void calc_LHC_LogLikes_full(map_str_AnalysisLogLikes&amp; result)
    {
      using namespace Pipes::calc_LHC_LogLikes_full;
      AnalysisDataPointers ana = *(Dep::AllAnalysisNumbers);
      
      bool use_fulllikes = true;
      
      // If no events have been generated (xsec veto) or too many events have
      // failed, short-circut the loop and return delta log-likelihood = 0 for
      // every SR in each analysis.
      //
      /// @todo Needs more sophistication once we add analyses that don't use event generation.
      bool skip_calc = (not Dep::RunMC-&gt;event_gen_BYPASS &amp;&amp; (not Dep::RunMC-&gt;event_generation_began || Dep::RunMC-&gt;exceeded_maxFailedEvents) );
      
      
      // Get a pointer to the FullLikes backend functions.
      bool (*FileExists)(const str&amp;) = BEreq::FullLikes_FileExists.pointer();
      int (*ReadIn)(const str&amp;, const str&amp;) = BEreq::FullLikes_ReadIn.pointer();
      double (*Evaluate)(std::map&lt;str,double&gt;&amp;,const str&amp;) = BEreq::FullLikes_Evaluate.pointer();
      
      // Call the calc_LHC_LogLikes
      calc_LHC_LogLikes_common(result, use_fulllikes, ana, *runOptions, skip_calc, FileExists, ReadIn, Evaluate);
                               
    }

    /// Loop over all analyses and fill a map of AnalysisLogLikes objectss
    void calc_LHC_LogLikes(map_str_AnalysisLogLikes&amp; result)
    {
      using namespace Pipes::calc_LHC_LogLikes;
      AnalysisDataPointers ana = *(Dep::AllAnalysisNumbers);
      
      bool use_fulllikes = false;
    
      // If no events have been generated (xsec veto) or too many events have
      // failed, short-circut the loop and return delta log-likelihood = 0 for
      // every SR in each analysis.
      //
      /// @todo Needs more sophistication once we add analyses that don't use event generation.
      bool skip_calc = (not Dep::RunMC-&gt;event_gen_BYPASS &amp;&amp; (not Dep::RunMC-&gt;event_generation_began || Dep::RunMC-&gt;exceeded_maxFailedEvents) );
      

      // Call the calc_LHC_LogLikes
      calc_LHC_LogLikes_common(result, use_fulllikes, ana, *runOptions, skip_calc, nullptr, nullptr, nullptr);
      
    }



    /// Extract the combined log likelihood for each analysis
    void get_LHC_LogLike_per_analysis(map_str_dbl&amp; result)
    {
      using namespace Pipes::get_LHC_LogLike_per_analysis;

      std::stringstream summary_line;
      summary_line &lt;&lt; &quot;LHC loglikes per analysis: &quot;;

      for (const std::pair&lt;const str, AnalysisLogLikes&gt;&amp; pair : *Dep::LHC_LogLikes)
      {
        const str&amp; analysis_name = pair.first;
        const AnalysisLogLikes&amp; analysis_loglikes = pair.second;

        result[analysis_name] = analysis_loglikes.combination_loglike;

        summary_line &lt;&lt; analysis_name &lt;&lt; &quot;:&quot; &lt;&lt; analysis_loglikes.combination_loglike &lt;&lt; &quot;, &quot;;

        // Any alternative combined likelihoods?
        for (const auto&amp; map_element : analysis_loglikes.alt_combination_loglikes)
        {
          const str&amp; alt_loglike_key = map_element.first;
          const double&amp; alt_combination_loglike = map_element.second;
          result[analysis_name + &quot;__&quot; + alt_loglike_key + &quot;_LogLike&quot;] = alt_combination_loglike;
        }

      }
      logger() &lt;&lt; LogTags::debug &lt;&lt; summary_line.str() &lt;&lt; EOM;
    }


    /// Extract the log likelihood for each SR
    void get_LHC_LogLike_per_SR(map_str_dbl&amp; result)
    {
      using namespace Pipes::get_LHC_LogLike_per_SR;

      std::stringstream summary_line;
      summary_line &lt;&lt; &quot;LHC loglikes per SR: &quot;;

      for (const std::pair&lt;const str, AnalysisLogLikes&gt;&amp; pair_i : *Dep::LHC_LogLikes)
      {
        const str&amp; analysis_name = pair_i.first;
        const AnalysisLogLikes&amp; analysis_loglikes = pair_i.second;

        summary_line &lt;&lt; analysis_name &lt;&lt; &quot;: &quot;;

        for (size_t sr_index = 0; sr_index &lt; analysis_loglikes.sr_loglikes.size(); ++sr_index)
        {
          const str&amp; sr_label = analysis_loglikes.sr_labels.at(sr_index);
          const double&amp; sr_loglike = analysis_loglikes.sr_loglikes.at(sr_index);

          str base_key = analysis_name + &quot;__&quot; + sr_label + &quot;__i&quot; + std::to_string(sr_index); // + &quot;__LogLike&quot;;
          result[base_key + &quot;__LogLike&quot;] = sr_loglike;

          summary_line &lt;&lt; sr_label + &quot;__i&quot; + std::to_string(sr_index) &lt;&lt; &quot;:&quot; &lt;&lt; sr_loglike &lt;&lt; &quot;, &quot;;

          // Any alternative likelihoods?
          for (const auto&amp; map_element : analysis_loglikes.alt_sr_loglikes)
          {
            const str&amp; alt_loglike_key = map_element.first;
            const double&amp; alt_sr_loglike = map_element.second.at(sr_index);
            result[base_key + &quot;__&quot; + alt_loglike_key + &quot;_LogLike&quot;] = alt_sr_loglike;
          }
        }

        result[analysis_name + &quot;__combined_LogLike&quot;] = analysis_loglikes.combination_loglike;

        // Any alternative combined likelihoods?
        for (const auto&amp; map_element : analysis_loglikes.alt_combination_loglikes)
        {
          const str&amp; alt_loglike_key = map_element.first;
          const double&amp; alt_combination_loglike = map_element.second;
          result[analysis_name + &quot;__combined_&quot; + alt_loglike_key + &quot;_LogLike&quot;] = alt_combination_loglike;
        }

        summary_line &lt;&lt; &quot;combined_LogLike:&quot; &lt;&lt; analysis_loglikes.combination_loglike &lt;&lt; &quot;, &quot;;
      }
      logger() &lt;&lt; LogTags::debug &lt;&lt; summary_line.str() &lt;&lt; EOM;
    }


    /// Extract the labels for the SRs used in the analysis loglikes
    void get_LHC_LogLike_SR_labels(map_str_str&amp; result)
    {
      using namespace Pipes::get_LHC_LogLike_per_SR;
      for (const std::pair&lt;const str, AnalysisLogLikes&gt;&amp; pair_i : *Dep::LHC_LogLikes)
      {
        const str&amp; analysis_name = pair_i.first;
        const AnalysisLogLikes&amp; analysis_loglikes = pair_i.second;

        result[analysis_name] = analysis_loglikes.combination_sr_label;
      }
    }


    /// Extract the indices for the SRs used in the analysis loglikes
    /// @todo Switch result type to map_str_int once we have implemented a printer for this type
    void get_LHC_LogLike_SR_indices(map_str_dbl&amp; result)
    {
      using namespace Pipes::get_LHC_LogLike_per_SR;

      std::stringstream summary_line;
      summary_line &lt;&lt; &quot;LHC loglike SR indices: &quot;;

      // Loop over analyses
      for (const std::pair&lt;const str, AnalysisLogLikes&gt;&amp; pair_i : *Dep::LHC_LogLikes)
      {
        const str&amp; analysis_name = pair_i.first;
        const AnalysisLogLikes&amp; analysis_loglikes = pair_i.second;

        result[analysis_name] = (double) analysis_loglikes.combination_sr_index;

        summary_line &lt;&lt; analysis_name &lt;&lt; &quot;:&quot; &lt;&lt; analysis_loglikes.combination_sr_index &lt;&lt; &quot;, &quot;;
      }
      logger() &lt;&lt; LogTags::debug &lt;&lt; summary_line.str() &lt;&lt; EOM;
    }


    /// Compute the total likelihood combining all analyses
    void calc_combined_LHC_LogLike(double&amp; result)
    {
      using namespace Pipes::calc_combined_LHC_LogLike;
      result = 0.0;

      static bool first = true;
      static const bool write_summary_to_log = runOptions-&gt;getValueOrDef&lt;bool&gt;(false, &quot;write_summary_to_log&quot;);
      static const str alt_loglike_key = runOptions-&gt;getValueOrDef&lt;str&gt;(&quot;&quot;, &quot;alt_loglike&quot;);
      static bool use_alt_loglike = !alt_loglike_key.empty();

      std::stringstream summary_line_combined_loglike; 
      summary_line_combined_loglike &lt;&lt; &quot;calc_combined_LHC_LogLike: combined LogLike: &quot;;
      std::stringstream summary_line_skipped_analyses;
      summary_line_skipped_analyses &lt;&lt; &quot;calc_combined_LHC_LogLike: skipped analyses: &quot;;
      std::stringstream summary_line_included_analyses;
      summary_line_included_analyses &lt;&lt; &quot;calc_combined_LHC_LogLike: included analyses: &quot;;

      // Read analysis names from the yaml file
      std::vector&lt;str&gt; default_skip_analyses;  // The default is empty lists of analyses to skip
      static const std::vector&lt;str&gt; skip_analyses = runOptions-&gt;getValueOrDef&lt;std::vector&lt;str&gt; &gt;(default_skip_analyses, &quot;skip_analyses&quot;);

      // If too many events have failed, do the conservative thing and return delta log-likelihood = 0
      if (Dep::RunMC-&gt;exceeded_maxFailedEvents)
      {
        #ifdef COLLIDERBIT_DEBUG
          cout &lt;&lt; DEBUG_PREFIX &lt;&lt; &quot;calc_combined_LHC_LogLike: Too many failed events. Will be conservative and return a delta log-likelihood of 0.&quot; &lt;&lt; endl;
        #endif
        return;
      }

      // Loop over analyses and calculate the total observed dLL
      for (const std::pair&lt;const str, AnalysisLogLikes&gt;&amp; pair : *Dep::LHC_LogLikes)
      {
        const str&amp; analysis_name = pair.first;
        const AnalysisLogLikes&amp; analysis_loglikes = pair.second;

        // On the first iteration we check that if the alt_loglike option is specified, the input 
        // string must exist as a key in the AnalysisLogLikes::alt_combination_loglikes map
        if (first)
        {
          if (use_alt_loglike)
          {
            if (analysis_loglikes.alt_combination_loglikes.count(alt_loglike_key) == 0)
            {
              ColliderBit_error().set_fatal(true); // This one must regarded fatal since there is something wrong in the user input
              ColliderBit_error().raise(LOCAL_INFO, &quot;The provided 'alt_loglike' key '&quot; + alt_loglike_key + &quot;' is unknown. Please check your YAML file.&quot;);
            }
          }
          first = false;
        }

        // Get the loglike value.
        // Use the regular loglike or an alternative one?
        double use_analysis_loglike = 0.0;
        if (use_alt_loglike) 
        {
          use_analysis_loglike = analysis_loglikes.alt_combination_loglikes.at(alt_loglike_key);
        }
        else
        {
          use_analysis_loglike = analysis_loglikes.combination_loglike;
        }

        // If the analysis name is in skip_analyses, don't add its loglike to the total loglike.
        if (std::find(skip_analyses.begin(), skip_analyses.end(), analysis_name) != skip_analyses.end())
        {
          #ifdef COLLIDERBIT_DEBUG
            cout.precision(5);
            cout &lt;&lt; DEBUG_PREFIX &lt;&lt; &quot;calc_combined_LHC_LogLike: Leaving out analysis &quot; &lt;&lt; analysis_name &lt;&lt; &quot; with LogL = &quot; &lt;&lt; use_analysis_loglike &lt;&lt; endl;
          #endif

          // Add to log summary
          if(write_summary_to_log)
          {
            summary_line_skipped_analyses &lt;&lt; analysis_name &lt;&lt; &quot;__LogLike:&quot; &lt;&lt; use_analysis_loglike &lt;&lt; &quot;, &quot;;
          }

          continue;
        }

        // OK, analysis is not in the skip_analysis list, so we proceed to add the analysis loglike

        // If using capped likelihood for each individual analysis, set use_analysis_loglike = min(use_analysis_loglike, 0)
        static const bool use_cap_loglike_individual = runOptions-&gt;getValueOrDef&lt;bool&gt;(false, &quot;cap_loglike_individual_analyses&quot;);
        if (use_cap_loglike_individual)
        {
          result += std::min(use_analysis_loglike, 0.0);
        }
        else
        {
          result += use_analysis_loglike;
        }

        // Add to log summary
        if(write_summary_to_log)
        {
          summary_line_included_analyses &lt;&lt; analysis_name &lt;&lt; &quot;__LogLike:&quot; &lt;&lt; use_analysis_loglike &lt;&lt; &quot;, &quot;;
        }

        #ifdef COLLIDERBIT_DEBUG
          cout.precision(5);
          cout &lt;&lt; DEBUG_PREFIX &lt;&lt; &quot;calc_combined_LHC_LogLike: Analysis &quot; &lt;&lt; analysis_name &lt;&lt; &quot; contributes with a LogL = &quot; &lt;&lt; use_analysis_loglike &lt;&lt; endl;
        #endif
      }


      #ifdef COLLIDERBIT_DEBUG
        cout &lt;&lt; DEBUG_PREFIX &lt;&lt; &quot;calc_combined_LHC_LogLike: LHC_Combined_LogLike = &quot; &lt;&lt; result &lt;&lt; endl;
      #endif

      // If using a &quot;global&quot; capped likelihood, set result = min(result,0)
      static const bool use_cap_loglike = runOptions-&gt;getValueOrDef&lt;bool&gt;(false, &quot;cap_loglike&quot;);
      if (use_cap_loglike)
      {
        result = std::min(result, 0.0);
      }

      // Write log summary
      if(write_summary_to_log)
      {
        summary_line_combined_loglike &lt;&lt; result;

        logger() &lt;&lt; summary_line_combined_loglike.str() &lt;&lt; EOM;
        logger() &lt;&lt; summary_line_included_analyses.str() &lt;&lt; EOM;
        logger() &lt;&lt; summary_line_skipped_analyses.str() &lt;&lt; EOM;
      }  
    }


    /// A dummy log-likelihood that helps the scanner track a given 
    /// range of collider log-likelihood values
    void calc_LHC_LogLike_scan_guide(double&amp; result)
    {
      using namespace Pipes::calc_LHC_LogLike_scan_guide;
      result = 0.0;

      static const bool write_summary_to_log = runOptions-&gt;getValueOrDef&lt;bool&gt;(false, &quot;write_summary_to_log&quot;);
      static const double target_LHC_loglike = runOptions-&gt;getValue&lt;double&gt;(&quot;target_LHC_loglike&quot;);
      static const double target_width = runOptions-&gt;getValue&lt;double&gt;(&quot;width_LHC_loglike&quot;);

      // Get the combined LHC loglike
      double LHC_loglike = *Dep::LHC_Combined_LogLike;

      // Calculate the dummy scan guide loglike using a gaussian centered on the target LHC loglike value
      result = Stats::gaussian_loglikelihood(LHC_loglike, target_LHC_loglike, 0.0, target_width, false);

      // Write log summary
      if(write_summary_to_log)
      {
        std::stringstream summary_line; 
        summary_line &lt;&lt; &quot;LHC_LogLike_scan_guide: &quot; &lt;&lt; result;
        logger() &lt;&lt; summary_line.str() &lt;&lt; EOM;
      }  
    }

  }
}
</code></pre><hr><p>Updated on 2025-02-12 at 16:10:36 +0000</p></main></div></div></div><footer class="footer text-muted"><div class=container-xxl><div class=row><div class="col-lg-8 order-last order-lg-first"><ul class=list-inline><li class=list-inline-item>Powered by <a href=https://gohugo.io/>Hugo</a> and <a href=https://getdoks.org/>Doks</a></li></ul></div><div class="col-lg-8 order-first order-lg-last text-lg-end"><ul class=list-inline><li class=list-inline-item><a href=/license/>License</a></li></ul></div></div></div></footer><script src=/js/bootstrap.min.862c9eb8ab97f8c1c8584b21ce31113d8553917669561b040011b0061009a0b6c7a6b61fb659f56eabfa9f45259f001417dba1d65b229f685f3cdbb709482f8e.js integrity="sha512-hiyeuKuX+MHIWEshzjERPYVTkXZpVhsEABGwBhAJoLbHprYftln1bqv6n0UlnwAUF9uh1lsin2hfPNu3CUgvjg==" crossorigin=anonymous defer></script>
<script src=/js/highlight.min.3fa03d1d36ae7a66d6d5d2e19796832d40b4a5417eaaae1dfba8837d033467084e8c051f25aee596d415422573116115ccc5c2b29970d3490dafdce1a920a402.js integrity="sha512-P6A9HTauembW1dLhl5aDLUC0pUF+qq4d+6iDfQM0ZwhOjAUfJa7lltQVQiVzEWEVzMXCsplw00kNr9zhqSCkAg==" crossorigin=anonymous defer></script>
<script src=/main.min.04459eeb2d9d601a3ccc10d2699fb84f0442d5f5d3a16372b023be7564838ed2a755b908598f715d6b42c0be95895835b2e872f4fa4acd028ef3904671a92f1a.js integrity="sha512-BEWe6y2dYBo8zBDSaZ+4TwRC1fXToWNysCO+dWSDjtKnVbkIWY9xXWtCwL6ViVg1suhy9PpKzQKO85BGcakvGg==" crossorigin=anonymous defer></script>
<script src=https://gambitbsm.org/index.min.b404f89f15d72e76ab8c792800be55a6b28c85d9f5ed5c51512423e7307aa39fd452d558ac384b69d6ba1bdfd73766058356d63e0068329229eec6bc310e1eda.js integrity="sha512-tAT4nxXXLnarjHkoAL5VprKMhdn17VxRUSQj5zB6o5/UUtVYrDhLada6G9/XN2YFg1bWPgBoMpIp7sa8MQ4e2g==" crossorigin=anonymous defer></script></body></html>